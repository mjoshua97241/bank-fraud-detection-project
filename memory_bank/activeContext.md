# Active Context

## Current work focus

*   Integrating the Memory Bank system into the workflow.
*   Refining data dictionary generation and access.
*   **Implementing modular data pipeline:**
    *   `1.0-mjv-data-ingestion-and-anonymization.py` (data ingestion and anonymization)
    *   `2.0-mjv-data-preparation.py` (data preparation, cleaning, and initial filtering, extracted from original `1.0-mjv-initial-data-exploration.py`)
    *   `3.0-mjv-feature-selection-and-eda.py` (feature selection and initial EDA, extracted from original `1.0-mjv-initial-data-exploration.py`)
*   Adopting a new Jupyter Notebook workflow: read `.ipynb`, edit `.py`.
*   **Feature selection and initial EDA are complete, resulting in a refined dataset for further analysis.**
*   **IV and WoE calculation code for categorical and numerical features has been refined, ensuring robust column handling, consistent naming, and rounding to 2 decimal places for IV/WoE and 4 for percentages. Detailed IV results for each feature are now saved to individual CSV files in `references/iv_details/`.**
*   **Columns have been dropped based on IV calculation and feature selection criteria.**
*   **IV interpretation and reasons in the Markdown table and `get_predictive_power` functions in the feature selection script have been updated.**
*   **`4.0-mjv-eda-final-features.ipynb` has been initialized, `FEATURE_CATEGORIES` populated, `plot_feature_iv` function implemented, and feature lists refined based on IV for Transaction Size and Frequency, Network Behaviors, Time-Based Behaviors, and Fund Flow Patterns. The `plot_feature_distribution` function now reads IV details from individual CSV files in `references/iv_details/`.**

## Recent changes

*   **Refactored data pipeline into modular scripts:**
    *   `1.0-mjv-data-ingestion-and-anonymization.py` (content from `notebooks/1.0-mjv-initial-data-exploration.ipynb`)
    *   `2.0-mjv-data-preparation.py` (placeholder created)
    *   `3.0-mjv-feature-selection-and-eda.py` (content from original `notebooks/to_be_deleted/py_version/1.0-mjv-initial-data-exploration.py`)
*   **Processed data from `3.0-mjv-feature-selection-and-eda.py` is now saved as `3.0_selected_features.parquet` for subsequent analysis. Detailed IV results for individual features are saved to `references/iv_details/` as separate CSV files.**
*   **Plots generated by `2.0-mjv-data-preparation.py` and `3.0-mjv-feature-selection-and-eda.py` are now saved to `reports/figures/`.**
*   Corrected `PROJECT_ROOT` and `project_root` definitions in `bank_fraud/config.py` and `bank_fraud/utils/data_dictionary_generator.py`.
*   Adjusted `DATA_DICTIONARIES_DIR` in `bank_fraud/config.py` to point directly to `REFERENCES_DIR`.
*   Modified Jupyter Notebook print statement for `exported_path` to show relative path.
*   Created `data_dictionary_explanation.md` for Jupyter Notebook.
*   Moved `eda_checklist.md` to `notebooks/to_be_deleted/`.
*   Updated `.cursorrules` with agent persona.
*   **Created `iv_calculation.py` in `notebooks/to_be_deleted/` for categorical IV/WoE calculation.**
*   **Created `process_binning_rules.py` in `bank_fraud/utils/` and executed it to pre-process numerical binning rules.**
*   **Generated `numerical_binning_rules_processed.csv` in `references/`.**
*   **Integrating pre-processed binning rules into the feature selection script for optimized numerical IV calculation and fixed binning issues.**

## Next steps

*   Perform detailed EDA for final features in `4.0-mjv-eda-final-features.ipynb`, categorized by:
    *   Profile Traits
    *   Transaction Size and Frequency
    *   Network Behaviors
    *   Time-Based Behavors
    *   Fund Flow Patterns
*   Create bar graphs based on `categorical_iv_details.csv` and `numerical_iv_details.csv` for the features in each category.
*   Provide interpretation related to fraud for each bar graph.
*   Plan the subsequent steps (model training and evaluation, reporting and visualization components).

## Active decisions and considerations

*   Using a Markdown-based Memory Bank system for project context.
*   Ensuring consistent path management across the project.
*   Ensuring consistent application of the expert data scientist persona.
*   Using `nbconvert` for robust `.ipynb` file interaction.
*   **Reminder for IV Analysis:** Investigate 2815 `CONFIRMED_FRAUD` accounts with zero PESONET/INSTAPAY transactions during IV analysis to understand their fraud patterns.
*   **WoE and IV calculation for categorical features will use the `iv_calculation.py` script.**
*   **Numerical features will be binned using user-provided specific definitions before IV calculation.**
*   **Decision to pre-process numerical binning rules for optimization.**
