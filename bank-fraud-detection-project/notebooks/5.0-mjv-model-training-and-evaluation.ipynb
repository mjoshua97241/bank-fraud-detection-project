{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f4da02",
   "metadata": {},
   "source": [
    "# 5.0 - Model Training, Evaluation, and Business Simulation\n",
    "\n",
    "_by Michael Joshua Vargas_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d454bf",
   "metadata": {},
   "source": [
    "This notebook implements the full machine learning workflow. It covers:\n",
    "1.  **Data Preparation**: Loading the final feature set and splitting it into training, validation, and holdout sets.\n",
    "2.  **Preprocessing**: Creating a robust pipeline to scale numerical features and one-hot encode categorical features.\n",
    "3.  **Model Tuning**: Training and tuning two separate XGBoost models optimized for different business goals (Precision and AUC-PR).\n",
    "4.  **Business Evaluation**: Using the tuned models on the holdout set to simulate a real-world, cost-sensitive fraud detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d58ca4",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654181c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e50ef",
   "metadata": {},
   "source": [
    "#### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edbd0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "# --- Preprocessing & Modeling ---\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# --- Evaluation ---\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    brier_score_loss\n",
    ")\n",
    "from IPython.display import display # Added for display function\n",
    "\n",
    "# --- Model Persistence & Visualization ---\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress all warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca4cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Path Setup ---\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = Path(os.getcwd())\n",
    "\n",
    "# Navigate up one level to reach the project root directory\n",
    "project_root = notebook_dir.parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import from config.py\n",
    "from bank_fraud.config import PROCESSED_DATA_DIR, REFERENCES_DIR, MODELS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcbba70",
   "metadata": {},
   "source": [
    "### Load Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c4c38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully from: data\\processed\\3.0_selected_features.parquet\n",
      "Dataset shape: (493189, 65)\n"
     ]
    }
   ],
   "source": [
    "# Load the final, curated dataset from the feature selection phase\n",
    "FINAL_DATA_PATH = PROCESSED_DATA_DIR / '3.0_selected_features.parquet'\n",
    "df = pd.read_parquet(FINAL_DATA_PATH)\n",
    "\n",
    "print(f\"Dataset loaded successfully from: {FINAL_DATA_PATH.relative_to(project_root)}\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb253a27",
   "metadata": {},
   "source": [
    "### Identify Feature Types and Define Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3786338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 identifier columns: ['profile_id', 'account_no']\n",
      "Identified 59 numerical features.\n",
      "Identified 3 categorical features.\n"
     ]
    }
   ],
   "source": [
    "# --- Dynamically Drop Identifier Columns ---\n",
    "\n",
    "# Load the identifier data dictionary to get the authoritative list of identifiers\n",
    "IDENTIFIER_DICT_PATH = REFERENCES_DIR / 'identifier_data_dictionary.csv'\n",
    "identifier_df = pd.read_csv(IDENTIFIER_DICT_PATH)\n",
    "all_identifiers = identifier_df['feature_name'].tolist()\n",
    "\n",
    "# Find which of these identifiers are actually present in our current DataFrame\n",
    "# This ensures the script doesn't fail if a column was already dropped in a previous step.\n",
    "identifiers_to_drop = [col for col in all_identifiers if col in df.columns]\n",
    "\n",
    "# Define the target variable\n",
    "TARGET_COL = 'fraud_status'\n",
    "\n",
    "# Define the feature matrix X by dropping the target and all identified identifiers\n",
    "X = df.drop(columns=[TARGET_COL] + identifiers_to_drop, errors='ignore')\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "print(f\"Dropped {len(identifiers_to_drop)} identifier columns: {identifiers_to_drop}\")\n",
    "\n",
    "\n",
    "# Identify numerical and categorical features from the final feature matrix X\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Identified {len(numerical_features)} numerical features.\")\n",
    "print(f\"Identified {len(categorical_features)} categorical features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ed50a",
   "metadata": {},
   "source": [
    "### Split Data into Training, Validation, and Holdout Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d94bdbf",
   "metadata": {},
   "source": [
    "We will perform a stratified split to ensure the proportion of fraud cases is consistent across all datasets.\n",
    "- **Training Set (70%)**: For training the model.\n",
    "- **Validation Set (15%)**: For tuning hyperparameters.\n",
    "- **Holdout Set (15%)**: For final, unbiased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ace76ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting complete.\n",
      "Training set shape:   (345232, 62)\n",
      "Validation set shape: (73978, 62)\n",
      "Holdout set shape:    (73979, 62)\n",
      "\n",
      "Proportion of fraud in each set:\n",
      "Training:   0.0166\n",
      "Validation: 0.0166\n",
      "Holdout:    0.0166\n"
     ]
    }
   ],
   "source": [
    "# First split: Create the training set (70%) and a temporary set (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.30, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Second split: Split the temporary set into validation (15%) and holdout (15%)\n",
    "# This is equivalent to splitting the 30% temp set in half (0.5)\n",
    "X_val, X_holdout, y_val, y_holdout = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=0.50, \n",
    "    random_state=42, \n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Data splitting complete.\")\n",
    "print(f\"Training set shape:   {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Holdout set shape:    {X_holdout.shape}\")\n",
    "print(\"\\nProportion of fraud in each set:\")\n",
    "print(f\"Training:   {y_train.mean():.4f}\")\n",
    "print(f\"Validation: {y_val.mean():.4f}\")\n",
    "print(f\"Holdout:    {y_holdout.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a001ec",
   "metadata": {},
   "source": [
    "### Establish Baseline with Proportion Chance Criterion (PCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475e2ca",
   "metadata": {},
   "source": [
    "Before building complex models, it's crucial to establish a baseline to understand the minimum performance we must exceed. For imbalanced classification tasks, simple accuracy can be misleading. The **Proportion Chance Criterion (PCC)** provides this baseline.\n",
    "\n",
    "The PCC represents the accuracy a naive model would achieve by always guessing the majority class. A common rule of thumb is that a useful model's accuracy should be at least 25% greater than the PCC.\n",
    "\n",
    "This calculation will demonstrate why we focus on metrics like Precision, Recall, and AUC-PR instead of accuracy alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93bd32b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion Chance Criterion (PCC): 96.74%\n",
      "1.25 * PCC Threshold: 120.92%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Calculate PCC on the training data\n",
    "class_counts = Counter(y_train)\n",
    "total_samples = len(y_train)\n",
    "\n",
    "pcc = ((class_counts[0] / total_samples)**2) + ((class_counts[1] / total_samples)**2)\n",
    "pcc_threshold = 1.25 * pcc\n",
    "\n",
    "print(f\"Proportion Chance Criterion (PCC): {pcc:.2%}\")\n",
    "print(f\"1.25 * PCC Threshold: {pcc_threshold:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14897f37",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "The PCC of approximately 0.97 indicates that a model that does nothing but predict 'NON_FRAUD' for every case would be about 97% accurate. This high value underscores the inadequacy of accuracy as a primary metric for this problem. Our model must demonstrate a much more nuanced understanding of the data to be considered effective, which is why our evaluation will focus on its ability to correctly identify the rare fraud cases (Precision and Recall)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c8523",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3eb3ce0",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Pipeline Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f91cca",
   "metadata": {},
   "source": [
    "We will create a preprocessing pipeline using `ColumnTransformer` to apply different transformations to different types of columns.\n",
    "\n",
    "- **Numerical Features**: Will be scaled using `StandardScaler`. This standardizes features by removing the mean and scaling to unit variance, which is crucial for the performance of many machine learning algorithms.\n",
    "- **Categorical Features**: Will be transformed using `OneHotEncoder`. This converts categorical variables into a numerical format that can be provided to the model. `handle_unknown='ignore'` ensures that if a new category appears in the validation or holdout data (that was not seen in the training data), it will be handled gracefully without causing an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1204eb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipeline created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create the preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep other columns (if any), though we expect none\n",
    ")\n",
    "\n",
    "print(\"Preprocessing pipeline created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43359a33",
   "metadata": {},
   "source": [
    "## 3. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa36ca1",
   "metadata": {},
   "source": [
    "### 3.1. Baseline Model Comparison (No Resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163b984",
   "metadata": {},
   "source": [
    "We will first evaluate a set of baseline models without any resampling techniques to establish a performance benchmark.\n",
    "This step helps us understand the inherent performance of different algorithms on our imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f658d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "\n",
    "def auto_ml(X, y, models_dict, preprocessor, cv, res_t=None):\n",
    "    \"\"\"\n",
    "    Applies preprocessing, optional resampling, and evaluates multiple models using cross-validation.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    results_formatted = {}\n",
    "\n",
    "    for model_name, model_instance in models_dict.items():\n",
    "        print(f\"\\n--- Evaluating {model_name} ---\")\n",
    "        \n",
    "        # Create a pipeline that includes preprocessing and the model\n",
    "        if res_t is not None:\n",
    "            # If resampling is applied, use ImbPipeline\n",
    "            pipeline = ImbPipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('resampler', res_t),\n",
    "                ('classifier', model_instance)\n",
    "            ])\n",
    "        else:\n",
    "            # Otherwise, use standard Pipeline\n",
    "            pipeline = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', model_instance)\n",
    "            ])\n",
    "\n",
    "        train_ap, val_ap = [], []\n",
    "        train_bal_acc, val_bal_acc = [], []\n",
    "        train_f1_w, val_f1_w = [], []\n",
    "        train_mcc, val_mcc = [], []\n",
    "        train_brier, val_brier = [], []\n",
    "        train_precision, val_precision = [], []\n",
    "        train_recall, val_recall = [], []\n",
    "        \n",
    "        fold_times = []\n",
    "\n",
    "        for fold, (train_index, val_index) in enumerate(cv.split(X, y)):\n",
    "            X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "            start_time = time.time()\n",
    "            pipeline.fit(X_train_fold, y_train_fold)\n",
    "            end_time = time.time()\n",
    "            fold_times.append(end_time - start_time)\n",
    "\n",
    "            # Predictions\n",
    "            train_preds = pipeline.predict(X_train_fold)\n",
    "            val_preds = pipeline.predict(X_val_fold)\n",
    "            \n",
    "            # Predict probabilities for metrics that require them\n",
    "            train_probas = pipeline.predict_proba(X_train_fold)[:, 1]\n",
    "            val_probas = pipeline.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "            # Calculate metrics\n",
    "            train_ap.append(average_precision_score(y_train_fold, train_probas))\n",
    "            val_ap.append(average_precision_score(y_val_fold, val_probas))\n",
    "\n",
    "            train_bal_acc.append(balanced_accuracy_score(y_train_fold, train_preds))\n",
    "            val_bal_acc.append(balanced_accuracy_score(y_val_fold, val_preds))\n",
    "\n",
    "            train_f1_w.append(f1_score(y_train_fold, train_preds, average='weighted'))\n",
    "            val_f1_w.append(f1_score(y_val_fold, val_preds, average='weighted'))\n",
    "\n",
    "            train_mcc.append(matthews_corrcoef(y_train_fold, train_preds))\n",
    "            val_mcc.append(matthews_corrcoef(y_val_fold, val_preds))\n",
    "            \n",
    "            train_brier.append(brier_score_loss(y_train_fold, train_probas))\n",
    "            val_brier.append(brier_score_loss(y_val_fold, val_probas))\n",
    "\n",
    "            train_precision.append(precision_score(y_train_fold, train_preds))\n",
    "            val_precision.append(precision_score(y_val_fold, val_preds))\n",
    "\n",
    "            train_recall.append(recall_score(y_train_fold, train_preds))\n",
    "            val_recall.append(recall_score(y_val_fold, val_preds))\n",
    "\n",
    "        # Store average results\n",
    "        results[model_name] = {\n",
    "            'Train AP': np.mean(train_ap),\n",
    "            'Val AP': np.mean(val_ap),\n",
    "            'Train BalAcc': np.mean(train_bal_acc),\n",
    "            'Val BalAcc': np.mean(val_bal_acc),\n",
    "            'Train F1_w': np.mean(train_f1_w),\n",
    "            'Val F1_w': np.mean(val_f1_w),\n",
    "            'Train MCC': np.mean(train_mcc),\n",
    "            'Val MCC': np.mean(val_mcc),\n",
    "            'Train Brier': np.mean(train_brier),\n",
    "            'Val Brier': np.mean(val_brier),\n",
    "            'Train Precision': np.mean(train_precision),\n",
    "            'Val Precision': np.mean(val_precision),\n",
    "            'Train Recall': np.mean(train_recall),\n",
    "            'Val Recall': np.mean(val_recall),\n",
    "            'Avg Run Time (s)': np.mean(fold_times)\n",
    "        }\n",
    "        \n",
    "        # Store formatted results\n",
    "        results_formatted[model_name] = {\n",
    "            'Train AP': f\"{np.mean(train_ap)*100:.2f}%\",\n",
    "            'Val AP': f\"{np.mean(val_ap)*100:.2f}%\",\n",
    "            'Train BalAcc': f\"{np.mean(train_bal_acc)*100:.2f}%\",\n",
    "            'Val BalAcc': f\"{np.mean(val_bal_acc)*100:.2f}%\",\n",
    "            'Train F1_w': f\"{np.mean(train_f1_w)*100:.2f}%\",\n",
    "            'Val F1_w': f\"{np.mean(val_f1_w)*100:.2f}%\",\n",
    "            'Train MCC': f\"{np.mean(train_mcc)*100:.2f}%\",\n",
    "            'Val MCC': f\"{np.mean(val_mcc)*100:.2f}%\",\n",
    "            'Train Brier': f\"{np.mean(train_brier)*100:.2f}%\",\n",
    "            'Val Brier': f\"{np.mean(val_brier)*100:.2f}%\",\n",
    "            'Train Precision': f\"{np.mean(train_precision)*100:.2f}%\",\n",
    "            'Val Precision': f\"{np.mean(val_precision)*100:.2f}%\",\n",
    "            'Train Recall': f\"{np.mean(train_recall)*100:.2f}%\",\n",
    "            'Val Recall': f\"{np.mean(val_recall)*100:.2f}%\",\n",
    "            'Avg Run Time (s)': f\"{np.mean(fold_times):.2f}\"\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(results).T, pd.DataFrame(results_formatted).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00045bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline models\n",
    "# For XGBoost, scale_pos_weight is calculated based on the training data imbalance\n",
    "# eval_metric is set to 'logloss' for general classification, but AUC-PR is also tracked\n",
    "models_dict = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(random_state=42, class_weight='balanced', max_depth=8, min_samples_leaf=20, ccp_alpha=0.001),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        scale_pos_weight=(len(y_train) - y_train.sum()) / y_train.sum(),\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss', # Use logloss for general evaluation, AUC-PR is tracked separately\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a86450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating LogisticRegression ---\n",
      "\n",
      "--- Evaluating GaussianNB ---\n",
      "\n",
      "--- Evaluating DecisionTreeClassifier ---\n",
      "\n",
      "--- Evaluating XGBoost ---\n",
      "\n",
      "--- Baseline Model Performance (No Resampling) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AP</th>\n",
       "      <th>Val AP</th>\n",
       "      <th>Train BalAcc</th>\n",
       "      <th>Val BalAcc</th>\n",
       "      <th>Train F1_w</th>\n",
       "      <th>Val F1_w</th>\n",
       "      <th>Train MCC</th>\n",
       "      <th>Val MCC</th>\n",
       "      <th>Train Brier</th>\n",
       "      <th>Val Brier</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Val Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Val Recall</th>\n",
       "      <th>Avg Run Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>54.72%</td>\n",
       "      <td>54.46%</td>\n",
       "      <td>79.89%</td>\n",
       "      <td>79.78%</td>\n",
       "      <td>96.69%</td>\n",
       "      <td>96.70%</td>\n",
       "      <td>35.84%</td>\n",
       "      <td>35.77%</td>\n",
       "      <td>9.94%</td>\n",
       "      <td>9.95%</td>\n",
       "      <td>22.13%</td>\n",
       "      <td>22.12%</td>\n",
       "      <td>63.55%</td>\n",
       "      <td>63.33%</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>20.19%</td>\n",
       "      <td>20.18%</td>\n",
       "      <td>75.51%</td>\n",
       "      <td>75.47%</td>\n",
       "      <td>97.37%</td>\n",
       "      <td>97.37%</td>\n",
       "      <td>36.90%</td>\n",
       "      <td>36.84%</td>\n",
       "      <td>3.09%</td>\n",
       "      <td>3.09%</td>\n",
       "      <td>27.49%</td>\n",
       "      <td>27.44%</td>\n",
       "      <td>53.40%</td>\n",
       "      <td>53.33%</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>27.36%</td>\n",
       "      <td>26.92%</td>\n",
       "      <td>78.88%</td>\n",
       "      <td>78.63%</td>\n",
       "      <td>96.69%</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>35.07%</td>\n",
       "      <td>34.70%</td>\n",
       "      <td>10.69%</td>\n",
       "      <td>10.71%</td>\n",
       "      <td>22.03%</td>\n",
       "      <td>21.77%</td>\n",
       "      <td>61.50%</td>\n",
       "      <td>61.02%</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>69.00%</td>\n",
       "      <td>55.85%</td>\n",
       "      <td>84.36%</td>\n",
       "      <td>78.30%</td>\n",
       "      <td>98.62%</td>\n",
       "      <td>98.25%</td>\n",
       "      <td>60.86%</td>\n",
       "      <td>50.16%</td>\n",
       "      <td>7.40%</td>\n",
       "      <td>7.70%</td>\n",
       "      <td>54.43%</td>\n",
       "      <td>45.18%</td>\n",
       "      <td>69.70%</td>\n",
       "      <td>57.78%</td>\n",
       "      <td>7.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Train AP  Val AP Train BalAcc Val BalAcc Train F1_w  \\\n",
       "LogisticRegression       54.72%  54.46%       79.89%     79.78%     96.69%   \n",
       "GaussianNB               20.19%  20.18%       75.51%     75.47%     97.37%   \n",
       "DecisionTreeClassifier   27.36%  26.92%       78.88%     78.63%     96.69%   \n",
       "XGBoost                  69.00%  55.85%       84.36%     78.30%     98.62%   \n",
       "\n",
       "                       Val F1_w Train MCC Val MCC Train Brier Val Brier  \\\n",
       "LogisticRegression       96.70%    35.84%  35.77%       9.94%     9.95%   \n",
       "GaussianNB               97.37%    36.90%  36.84%       3.09%     3.09%   \n",
       "DecisionTreeClassifier   96.67%    35.07%  34.70%      10.69%    10.71%   \n",
       "XGBoost                  98.25%    60.86%  50.16%       7.40%     7.70%   \n",
       "\n",
       "                       Train Precision Val Precision Train Recall Val Recall  \\\n",
       "LogisticRegression              22.13%        22.12%       63.55%     63.33%   \n",
       "GaussianNB                      27.49%        27.44%       53.40%     53.33%   \n",
       "DecisionTreeClassifier          22.03%        21.77%       61.50%     61.02%   \n",
       "XGBoost                         54.43%        45.18%       69.70%     57.78%   \n",
       "\n",
       "                       Avg Run Time (s)  \n",
       "LogisticRegression                 3.78  \n",
       "GaussianNB                         1.30  \n",
       "DecisionTreeClassifier             4.97  \n",
       "XGBoost                            7.28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Run baseline evaluation\n",
    "baseline_results, baseline_results_formatted = auto_ml(X_train, y_train, models_dict, preprocessor, cv)\n",
    "\n",
    "print(\"\\n--- Baseline Model Performance (No Resampling) ---\")\n",
    "display(baseline_results_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c214b2a5",
   "metadata": {},
   "source": [
    "### 3.2. Resampling Techniques Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507fe23b",
   "metadata": {},
   "source": [
    "Now, we will evaluate the impact of different resampling techniques on model performance.\n",
    "We will compare RandomOverSampler, SMOTE, and RandomUnderSampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "458e784f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating with RandomOverSampler ---\n",
      "\n",
      "--- Evaluating LogisticRegression ---\n",
      "\n",
      "--- Evaluating GaussianNB ---\n",
      "\n",
      "--- Evaluating DecisionTreeClassifier ---\n",
      "\n",
      "--- Evaluating XGBoost ---\n",
      "\n",
      "--- Evaluating with SMOTE ---\n",
      "\n",
      "--- Evaluating LogisticRegression ---\n",
      "\n",
      "--- Evaluating GaussianNB ---\n",
      "\n",
      "--- Evaluating DecisionTreeClassifier ---\n",
      "\n",
      "--- Evaluating XGBoost ---\n",
      "\n",
      "--- Evaluating with RandomUnderSampler ---\n",
      "\n",
      "--- Evaluating LogisticRegression ---\n",
      "\n",
      "--- Evaluating GaussianNB ---\n",
      "\n",
      "--- Evaluating DecisionTreeClassifier ---\n",
      "\n",
      "--- Evaluating XGBoost ---\n",
      "\n",
      "--- Model Performance with Resampling ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AP</th>\n",
       "      <th>Val AP</th>\n",
       "      <th>Train BalAcc</th>\n",
       "      <th>Val BalAcc</th>\n",
       "      <th>Train F1_w</th>\n",
       "      <th>Val F1_w</th>\n",
       "      <th>Train MCC</th>\n",
       "      <th>Val MCC</th>\n",
       "      <th>Train Brier</th>\n",
       "      <th>Val Brier</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Val Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Val Recall</th>\n",
       "      <th>Avg Run Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression + RandomOverSampler</th>\n",
       "      <td>54.71%</td>\n",
       "      <td>54.44%</td>\n",
       "      <td>79.87%</td>\n",
       "      <td>79.75%</td>\n",
       "      <td>96.66%</td>\n",
       "      <td>96.66%</td>\n",
       "      <td>35.65%</td>\n",
       "      <td>35.54%</td>\n",
       "      <td>9.95%</td>\n",
       "      <td>9.95%</td>\n",
       "      <td>21.92%</td>\n",
       "      <td>21.87%</td>\n",
       "      <td>63.56%</td>\n",
       "      <td>63.33%</td>\n",
       "      <td>8.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB + RandomOverSampler</th>\n",
       "      <td>19.94%</td>\n",
       "      <td>19.91%</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>75.57%</td>\n",
       "      <td>97.32%</td>\n",
       "      <td>97.32%</td>\n",
       "      <td>36.54%</td>\n",
       "      <td>36.50%</td>\n",
       "      <td>3.17%</td>\n",
       "      <td>3.17%</td>\n",
       "      <td>26.87%</td>\n",
       "      <td>26.84%</td>\n",
       "      <td>53.68%</td>\n",
       "      <td>53.60%</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier + RandomOverSampler</th>\n",
       "      <td>27.67%</td>\n",
       "      <td>27.34%</td>\n",
       "      <td>78.85%</td>\n",
       "      <td>78.60%</td>\n",
       "      <td>96.77%</td>\n",
       "      <td>96.74%</td>\n",
       "      <td>35.54%</td>\n",
       "      <td>35.17%</td>\n",
       "      <td>10.67%</td>\n",
       "      <td>10.68%</td>\n",
       "      <td>22.63%</td>\n",
       "      <td>22.38%</td>\n",
       "      <td>61.30%</td>\n",
       "      <td>60.81%</td>\n",
       "      <td>10.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost + RandomOverSampler</th>\n",
       "      <td>67.67%</td>\n",
       "      <td>52.39%</td>\n",
       "      <td>64.12%</td>\n",
       "      <td>58.33%</td>\n",
       "      <td>43.40%</td>\n",
       "      <td>42.83%</td>\n",
       "      <td>8.06%</td>\n",
       "      <td>4.77%</td>\n",
       "      <td>60.80%</td>\n",
       "      <td>61.27%</td>\n",
       "      <td>2.30%</td>\n",
       "      <td>2.04%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>88.83%</td>\n",
       "      <td>8.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression + SMOTE</th>\n",
       "      <td>55.01%</td>\n",
       "      <td>54.75%</td>\n",
       "      <td>79.85%</td>\n",
       "      <td>79.75%</td>\n",
       "      <td>96.69%</td>\n",
       "      <td>96.70%</td>\n",
       "      <td>35.82%</td>\n",
       "      <td>35.75%</td>\n",
       "      <td>9.97%</td>\n",
       "      <td>9.98%</td>\n",
       "      <td>22.13%</td>\n",
       "      <td>22.12%</td>\n",
       "      <td>63.47%</td>\n",
       "      <td>63.26%</td>\n",
       "      <td>8.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB + SMOTE</th>\n",
       "      <td>20.01%</td>\n",
       "      <td>20.01%</td>\n",
       "      <td>75.71%</td>\n",
       "      <td>75.67%</td>\n",
       "      <td>97.32%</td>\n",
       "      <td>97.32%</td>\n",
       "      <td>36.59%</td>\n",
       "      <td>36.52%</td>\n",
       "      <td>3.18%</td>\n",
       "      <td>3.19%</td>\n",
       "      <td>26.82%</td>\n",
       "      <td>26.78%</td>\n",
       "      <td>53.91%</td>\n",
       "      <td>53.81%</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier + SMOTE</th>\n",
       "      <td>25.23%</td>\n",
       "      <td>25.20%</td>\n",
       "      <td>76.93%</td>\n",
       "      <td>76.92%</td>\n",
       "      <td>97.88%</td>\n",
       "      <td>97.88%</td>\n",
       "      <td>43.73%</td>\n",
       "      <td>43.66%</td>\n",
       "      <td>8.87%</td>\n",
       "      <td>8.88%</td>\n",
       "      <td>36.27%</td>\n",
       "      <td>36.17%</td>\n",
       "      <td>55.52%</td>\n",
       "      <td>55.49%</td>\n",
       "      <td>21.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost + SMOTE</th>\n",
       "      <td>56.58%</td>\n",
       "      <td>50.04%</td>\n",
       "      <td>64.47%</td>\n",
       "      <td>58.80%</td>\n",
       "      <td>44.77%</td>\n",
       "      <td>44.35%</td>\n",
       "      <td>8.15%</td>\n",
       "      <td>4.96%</td>\n",
       "      <td>59.21%</td>\n",
       "      <td>59.58%</td>\n",
       "      <td>2.32%</td>\n",
       "      <td>2.06%</td>\n",
       "      <td>99.53%</td>\n",
       "      <td>88.48%</td>\n",
       "      <td>9.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression + RandomUnderSampler</th>\n",
       "      <td>51.96%</td>\n",
       "      <td>51.57%</td>\n",
       "      <td>79.73%</td>\n",
       "      <td>79.64%</td>\n",
       "      <td>96.51%</td>\n",
       "      <td>96.51%</td>\n",
       "      <td>34.63%</td>\n",
       "      <td>34.56%</td>\n",
       "      <td>9.97%</td>\n",
       "      <td>9.98%</td>\n",
       "      <td>20.82%</td>\n",
       "      <td>20.81%</td>\n",
       "      <td>63.54%</td>\n",
       "      <td>63.36%</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB + RandomUnderSampler</th>\n",
       "      <td>18.23%</td>\n",
       "      <td>18.22%</td>\n",
       "      <td>75.99%</td>\n",
       "      <td>75.96%</td>\n",
       "      <td>97.06%</td>\n",
       "      <td>97.05%</td>\n",
       "      <td>34.83%</td>\n",
       "      <td>34.74%</td>\n",
       "      <td>3.61%</td>\n",
       "      <td>3.62%</td>\n",
       "      <td>24.16%</td>\n",
       "      <td>24.07%</td>\n",
       "      <td>54.91%</td>\n",
       "      <td>54.88%</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier + RandomUnderSampler</th>\n",
       "      <td>28.80%</td>\n",
       "      <td>28.44%</td>\n",
       "      <td>78.78%</td>\n",
       "      <td>78.59%</td>\n",
       "      <td>96.63%</td>\n",
       "      <td>96.60%</td>\n",
       "      <td>34.77%</td>\n",
       "      <td>34.39%</td>\n",
       "      <td>10.72%</td>\n",
       "      <td>10.74%</td>\n",
       "      <td>21.81%</td>\n",
       "      <td>21.49%</td>\n",
       "      <td>61.40%</td>\n",
       "      <td>61.04%</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost + RandomUnderSampler</th>\n",
       "      <td>59.57%</td>\n",
       "      <td>54.16%</td>\n",
       "      <td>58.84%</td>\n",
       "      <td>56.47%</td>\n",
       "      <td>29.60%</td>\n",
       "      <td>29.34%</td>\n",
       "      <td>5.96%</td>\n",
       "      <td>4.37%</td>\n",
       "      <td>68.43%</td>\n",
       "      <td>68.61%</td>\n",
       "      <td>2.01%</td>\n",
       "      <td>1.91%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>95.44%</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Train AP  Val AP Train BalAcc  \\\n",
       "LogisticRegression + RandomOverSampler        54.71%  54.44%       79.87%   \n",
       "GaussianNB + RandomOverSampler                19.94%  19.91%       75.61%   \n",
       "DecisionTreeClassifier + RandomOverSampler    27.67%  27.34%       78.85%   \n",
       "XGBoost + RandomOverSampler                   67.67%  52.39%       64.12%   \n",
       "LogisticRegression + SMOTE                    55.01%  54.75%       79.85%   \n",
       "GaussianNB + SMOTE                            20.01%  20.01%       75.71%   \n",
       "DecisionTreeClassifier + SMOTE                25.23%  25.20%       76.93%   \n",
       "XGBoost + SMOTE                               56.58%  50.04%       64.47%   \n",
       "LogisticRegression + RandomUnderSampler       51.96%  51.57%       79.73%   \n",
       "GaussianNB + RandomUnderSampler               18.23%  18.22%       75.99%   \n",
       "DecisionTreeClassifier + RandomUnderSampler   28.80%  28.44%       78.78%   \n",
       "XGBoost + RandomUnderSampler                  59.57%  54.16%       58.84%   \n",
       "\n",
       "                                            Val BalAcc Train F1_w Val F1_w  \\\n",
       "LogisticRegression + RandomOverSampler          79.75%     96.66%   96.66%   \n",
       "GaussianNB + RandomOverSampler                  75.57%     97.32%   97.32%   \n",
       "DecisionTreeClassifier + RandomOverSampler      78.60%     96.77%   96.74%   \n",
       "XGBoost + RandomOverSampler                     58.33%     43.40%   42.83%   \n",
       "LogisticRegression + SMOTE                      79.75%     96.69%   96.70%   \n",
       "GaussianNB + SMOTE                              75.67%     97.32%   97.32%   \n",
       "DecisionTreeClassifier + SMOTE                  76.92%     97.88%   97.88%   \n",
       "XGBoost + SMOTE                                 58.80%     44.77%   44.35%   \n",
       "LogisticRegression + RandomUnderSampler         79.64%     96.51%   96.51%   \n",
       "GaussianNB + RandomUnderSampler                 75.96%     97.06%   97.05%   \n",
       "DecisionTreeClassifier + RandomUnderSampler     78.59%     96.63%   96.60%   \n",
       "XGBoost + RandomUnderSampler                    56.47%     29.60%   29.34%   \n",
       "\n",
       "                                            Train MCC Val MCC Train Brier  \\\n",
       "LogisticRegression + RandomOverSampler         35.65%  35.54%       9.95%   \n",
       "GaussianNB + RandomOverSampler                 36.54%  36.50%       3.17%   \n",
       "DecisionTreeClassifier + RandomOverSampler     35.54%  35.17%      10.67%   \n",
       "XGBoost + RandomOverSampler                     8.06%   4.77%      60.80%   \n",
       "LogisticRegression + SMOTE                     35.82%  35.75%       9.97%   \n",
       "GaussianNB + SMOTE                             36.59%  36.52%       3.18%   \n",
       "DecisionTreeClassifier + SMOTE                 43.73%  43.66%       8.87%   \n",
       "XGBoost + SMOTE                                 8.15%   4.96%      59.21%   \n",
       "LogisticRegression + RandomUnderSampler        34.63%  34.56%       9.97%   \n",
       "GaussianNB + RandomUnderSampler                34.83%  34.74%       3.61%   \n",
       "DecisionTreeClassifier + RandomUnderSampler    34.77%  34.39%      10.72%   \n",
       "XGBoost + RandomUnderSampler                    5.96%   4.37%      68.43%   \n",
       "\n",
       "                                            Val Brier Train Precision  \\\n",
       "LogisticRegression + RandomOverSampler          9.95%          21.92%   \n",
       "GaussianNB + RandomOverSampler                  3.17%          26.87%   \n",
       "DecisionTreeClassifier + RandomOverSampler     10.68%          22.63%   \n",
       "XGBoost + RandomOverSampler                    61.27%           2.30%   \n",
       "LogisticRegression + SMOTE                      9.98%          22.13%   \n",
       "GaussianNB + SMOTE                              3.19%          26.82%   \n",
       "DecisionTreeClassifier + SMOTE                  8.88%          36.27%   \n",
       "XGBoost + SMOTE                                59.58%           2.32%   \n",
       "LogisticRegression + RandomUnderSampler         9.98%          20.82%   \n",
       "GaussianNB + RandomUnderSampler                 3.62%          24.16%   \n",
       "DecisionTreeClassifier + RandomUnderSampler    10.74%          21.81%   \n",
       "XGBoost + RandomUnderSampler                   68.61%           2.01%   \n",
       "\n",
       "                                            Val Precision Train Recall  \\\n",
       "LogisticRegression + RandomOverSampler             21.87%       63.56%   \n",
       "GaussianNB + RandomOverSampler                     26.84%       53.68%   \n",
       "DecisionTreeClassifier + RandomOverSampler         22.38%       61.30%   \n",
       "XGBoost + RandomOverSampler                         2.04%      100.00%   \n",
       "LogisticRegression + SMOTE                         22.12%       63.47%   \n",
       "GaussianNB + SMOTE                                 26.78%       53.91%   \n",
       "DecisionTreeClassifier + SMOTE                     36.17%       55.52%   \n",
       "XGBoost + SMOTE                                     2.06%       99.53%   \n",
       "LogisticRegression + RandomUnderSampler            20.81%       63.54%   \n",
       "GaussianNB + RandomUnderSampler                    24.07%       54.91%   \n",
       "DecisionTreeClassifier + RandomUnderSampler        21.49%       61.40%   \n",
       "XGBoost + RandomUnderSampler                        1.91%      100.00%   \n",
       "\n",
       "                                            Val Recall Avg Run Time (s)  \n",
       "LogisticRegression + RandomOverSampler          63.33%             8.93  \n",
       "GaussianNB + RandomOverSampler                  53.60%             2.29  \n",
       "DecisionTreeClassifier + RandomOverSampler      60.81%            10.69  \n",
       "XGBoost + RandomOverSampler                     88.83%             8.62  \n",
       "LogisticRegression + SMOTE                      63.26%             8.55  \n",
       "GaussianNB + SMOTE                              53.81%             2.92  \n",
       "DecisionTreeClassifier + SMOTE                  55.49%            21.57  \n",
       "XGBoost + SMOTE                                 88.48%             9.63  \n",
       "LogisticRegression + RandomUnderSampler         63.36%             1.13  \n",
       "GaussianNB + RandomUnderSampler                 54.88%             0.95  \n",
       "DecisionTreeClassifier + RandomUnderSampler     61.04%             1.08  \n",
       "XGBoost + RandomUnderSampler                    95.44%             1.67  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resamplers_dict = {\n",
    "    'RandomOverSampler': RandomOverSampler(random_state=42),\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'RandomUnderSampler': RandomUnderSampler(random_state=42)\n",
    "}\n",
    "\n",
    "resampling_results = {}\n",
    "resampling_results_formatted = {}\n",
    "\n",
    "for resampler_name, resampler_instance in resamplers_dict.items():\n",
    "    print(f\"\\n--- Evaluating with {resampler_name} ---\")\n",
    "    # For each resampler, evaluate all models\n",
    "    current_res_results, current_res_results_formatted = auto_ml(X_train, y_train, models_dict, preprocessor, cv, res_t=resampler_instance)\n",
    "    \n",
    "    # Store results, potentially renaming columns to indicate resampler\n",
    "    for model_name in current_res_results.index:\n",
    "        # Use a combined key for model and resampler\n",
    "        combined_key = f\"{model_name} + {resampler_name}\"\n",
    "        resampling_results[combined_key] = current_res_results.loc[model_name].to_dict()\n",
    "        resampling_results_formatted[combined_key] = current_res_results_formatted.loc[model_name].to_dict()\n",
    "\n",
    "resampling_results_df = pd.DataFrame(resampling_results).T\n",
    "resampling_results_formatted_df = pd.DataFrame(resampling_results_formatted).T\n",
    "\n",
    "print(\"\\n--- Model Performance with Resampling ---\")\n",
    "display(resampling_results_formatted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf98b9f",
   "metadata": {},
   "source": [
    "### 3.3. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3653e280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model performance saved to: reports\\model_evaluation\\baseline_model_performance.csv\n",
      "Resampling model performance saved to: reports\\model_evaluation\\resampling_model_performance.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the directory for saving model evaluation results\n",
    "MODEL_EVAL_DIR = project_root / 'reports' / 'model_evaluation'\n",
    "MODEL_EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save baseline results\n",
    "baseline_results_formatted.to_csv(MODEL_EVAL_DIR / 'baseline_model_performance.csv', index=True)\n",
    "print(f\"Baseline model performance saved to: {MODEL_EVAL_DIR.relative_to(project_root) / 'baseline_model_performance.csv'}\")\n",
    "\n",
    "# Save resampling results\n",
    "resampling_results_formatted_df.to_csv(MODEL_EVAL_DIR / 'resampling_model_performance.csv', index=True)\n",
    "print(f\"Resampling model performance saved to: {MODEL_EVAL_DIR.relative_to(project_root) / 'resampling_model_performance.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7855e6ef",
   "metadata": {},
   "source": [
    "### 3.4. Decision on Resampling and Final Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a1a9f0",
   "metadata": {},
   "source": [
    "Based on the comparison of baseline models and models with resampling, we have made the following observations and decisions:\n",
    "\n",
    "**Analysis of Baseline Models (No Resampling):**\n",
    "- **XGBoost** demonstrated superior performance across key metrics, particularly `Val AP` (55.85%) and `Val Precision` (45.18%), compared to Logistic Regression, GaussianNB, and Decision Tree Classifier. This indicates its strong ability to identify fraud cases while maintaining a reasonable false positive rate without explicit external resampling.\n",
    "\n",
    "**Analysis of Resampling Techniques:**\n",
    "- For **XGBoost**, applying external resampling techniques (`RandomOverSampler`, `SMOTE`, `RandomUnderSampler`) generally led to a significant increase in `Val Recall` (e.g., up to 95.44% with RandomUnderSampler).\n",
    "- However, this increase in recall came at a substantial cost to `Val Precision` (dropping to as low as 1.91%) and `Val AP` (dropping to around 50-54%). This trade-off suggests that while more fraud cases are identified, a much higher number of non-fraud cases are also flagged as fraudulent, which is undesirable for the \"Auto-Blocking Leg\" that prioritizes minimizing false positives.\n",
    "- For other models (Logistic Regression, GaussianNB, Decision Tree), resampling did not consistently provide significant improvements in `Val AP` or `Val Precision` that would justify their use over XGBoost.\n",
    "\n",
    "**Decision on Resampling and Final Model Selection:**\n",
    "- We will proceed with **XGBoost without an explicit external resampling technique** for hyperparameter tuning. The `scale_pos_weight` parameter within XGBoost itself is already effectively handling the class imbalance by giving more importance to the minority class during training. This approach has shown the best balance between Precision and AUC-PR in our initial evaluations.\n",
    "\n",
    "Our primary optimization targets for tuning will remain:\n",
    "- **Precision**: Crucial for the \"Auto-Blocking Leg\" to minimize false positives.\n",
    "- **Average Precision (AUC-PR)**: A robust metric for overall ranking quality in imbalanced datasets, important for both legs of the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39b92b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review the tables above and the saved CSV files to compare model performance with and without resampling.\n",
      "Based on Precision and AUC-PR, decide which combination (model + optional resampler) to proceed with for hyperparameter tuning.\n",
      "This decision will inform the next steps in the notebook.\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for decision and next steps\n",
    "print(\"\\nReview the tables above and the saved CSV files to compare model performance with and without resampling.\")\n",
    "print(\"Based on Precision and AUC-PR, decide which combination (model + optional resampler) to proceed with for hyperparameter tuning.\")\n",
    "print(\"This decision will inform the next steps in the notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99aa65",
   "metadata": {},
   "source": [
    "### 3.5. Hyperparameter Tuning for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6869f",
   "metadata": {},
   "source": [
    "We will use a two-stage hyperparameter tuning process:\n",
    "1.  **Stage 1: RandomizedSearchCV**: To efficiently explore a broad range of hyperparameters and identify promising regions.\n",
    "2.  **Stage 2: GridSearchCV**: To perform a more exhaustive search within the narrowed, promising regions found by RandomizedSearchCV.\n",
    "\n",
    "We will perform this two-stage tuning for two separate objectives: one optimized for Precision and another for AUC-PR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81594cc",
   "metadata": {},
   "source": [
    "#### Stage 1: RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ced2ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading pre-trained models and tuning results ---\n",
      "Pre-trained models and Stage 1 tuning results loaded successfully. Skipping hyperparameter tuning.\n",
      "\n",
      "--- Stage 1: Randomized Search for Precision ---\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 75\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Stage 1: Randomized Search for Precision ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m random_search_precision \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     66\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline_for_tuning,\n\u001b[0;32m     67\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_distributions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     74\u001b[0m )\n\u001b[1;32m---> 75\u001b[0m \u001b[43mrandom_search_precision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest parameters from Randomized Search (Precision):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(random_search_precision\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the XGBoost model instance (without external resampler, as decided)\n",
    "# The scale_pos_weight is already set in the models_dict for XGBoost\n",
    "xgb_model_for_tuning = models_dict['XGBoost']\n",
    "\n",
    "# Create a pipeline for tuning that includes the preprocessor and the XGBoost model\n",
    "pipeline_for_tuning = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb_model_for_tuning)\n",
    "])\n",
    "\n",
    "# Define file paths for saved models\n",
    "precision_model_path = MODELS_DIR / 'best_xgb_precision_model.joblib'\n",
    "aucpr_model_path = MODELS_DIR / 'best_xgb_aucpr_model.joblib'\n",
    "\n",
    "# Check if models already exist\n",
    "if precision_model_path.exists() and aucpr_model_path.exists():\n",
    "    print(\"\\n--- Loading pre-trained models and tuning results ---\")\n",
    "    best_xgb_precision_model = joblib.load(precision_model_path)\n",
    "    best_xgb_aucpr_model = joblib.load(aucpr_model_path)\n",
    "\n",
    "    # Load Stage 1 best scores from CSVs for comparison in conditional saving\n",
    "    # Ensure these CSVs are saved by the previous run or manually created if skipping first run\n",
    "    try:\n",
    "        random_search_precision_results_df = pd.read_csv(MODEL_EVAL_DIR / 'random_search_precision_results.csv')\n",
    "        random_search_precision_best_score_stage1 = random_search_precision_results_df['mean_test_score'].max()\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: random_search_precision_results.csv not found. Cannot compare Stage 2 to Stage 1 for Precision.\")\n",
    "        random_search_precision_best_score_stage1 = -np.inf # Set to negative infinity so any Stage 2 score is better\n",
    "\n",
    "    try:\n",
    "        random_search_aucpr_results_df = pd.read_csv(MODEL_EVAL_DIR / 'random_search_aucpr_results.csv')\n",
    "        random_search_aucpr_best_score_stage1 = random_search_aucpr_results_df['mean_test_score'].max()\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: random_search_aucpr_results.csv not found. Cannot compare Stage 2 to Stage 1 for AUC-PR.\")\n",
    "        random_search_aucpr_best_score_stage1 = -np.inf # Set to negative infinity so any Stage 2 score is better\n",
    "\n",
    "    print(\"Pre-trained models and Stage 1 tuning results loaded successfully. Skipping hyperparameter tuning.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- Starting Hyperparameter Tuning (Models not found) ---\")\n",
    "    \"\"\"\n",
    "    We will use a two-stage hyperparameter tuning process:\n",
    "    1.  **Stage 1: RandomizedSearchCV**: To efficiently explore a broad range of hyperparameters and identify promising regions.\n",
    "    2.  **Stage 2: GridSearchCV**: To perform a more exhaustive search within the narrowed, promising regions found by RandomizedSearchCV.\n",
    "\n",
    "    We will perform this two-stage tuning for two separate objectives: one optimized for Precision and another for AUC-PR.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# --- Stage 1: RandomizedSearchCV ---\n",
    "# Define a broader parameter distribution for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'classifier__n_estimators': [100, 200, 300, 400, 500],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'classifier__max_depth': [3, 5, 7, 9],\n",
    "    'classifier__subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'classifier__gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'classifier__reg_alpha': [0, 0.001, 0.01, 0.1], # L1 regularization\n",
    "    'classifier__reg_lambda': [0, 0.001, 0.01, 0.1] # L2 regularization\n",
    "}\n",
    "\n",
    "# --- Randomized Search for Precision ---\n",
    "print(\"\\n--- Stage 1: Randomized Search for Precision ---\")\n",
    "random_search_precision = RandomizedSearchCV(\n",
    "    estimator=pipeline_for_tuning,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,  # Number of parameter settings that are sampled\n",
    "    scoring='precision',\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search_precision.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest parameters from Randomized Search (Precision):\")\n",
    "print(random_search_precision.best_params_)\n",
    "print(\"\\nBest Precision score from Randomized Search:\")\n",
    "print(random_search_precision.best_score_)\n",
    "\n",
    "# --- Randomized Search for AUC-PR ---\n",
    "print(\"\\n--- Stage 1: Randomized Search for AUC-PR ---\")\n",
    "random_search_aucpr = RandomizedSearchCV(\n",
    "    estimator=pipeline_for_tuning,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    scoring='average_precision',\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search_aucpr.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest parameters from Randomized Search (AUC-PR):\")\n",
    "print(random_search_aucpr.best_params_)\n",
    "print(\"\\nBest AUC-PR score from Randomized Search:\")\n",
    "print(random_search_aucpr.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3f5e0",
   "metadata": {},
   "source": [
    "Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save RandomizedSearchCV results for Precision\n",
    "pd.DataFrame(random_search_precision.cv_results_).to_csv(MODEL_EVAL_DIR / 'random_search_precision_results.csv', index=False)\n",
    "\n",
    "print(f\"Randomized Search (Precision) results saved to: {MODEL_EVAL_DIR.relative_to(project_root) / 'random_search_precision_results.csv'}\")\n",
    "\n",
    "# Save RandomizedSearchCV results for AUC-PR\n",
    "pd.DataFrame(random_search_aucpr.cv_results_).to_csv(MODEL_EVAL_DIR / 'random_search_aucpr_results.csv', index=False)\n",
    "\n",
    "print(f\"Randomized Search (AUC-PR) results saved to: {MODEL_EVAL_DIR.relative_to(project_root) / 'random_search_aucpr_results.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc2c74",
   "metadata": {},
   "source": [
    "#### Stage 2: GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b506ac",
   "metadata": {},
   "source": [
    "Define narrower parameter grids based on RandomizedSearchCV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7134c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_precision = random_search_precision.best_params_\n",
    "refined_param_grid_precision = {\n",
    "    'classifier__n_estimators': [max(100, best_params_precision['classifier__n_estimators'] - 25), best_params_precision['classifier__n_estimators'] + 25],\n",
    "    'classifier__learning_rate': [best_params_precision['classifier__learning_rate'] * 0.95, best_params_precision['classifier__learning_rate'] * 1.05],\n",
    "    'classifier__max_depth': [max(1, best_params_precision['classifier__max_depth']), best_params_precision['classifier__max_depth'] + 1],\n",
    "    'classifier__subsample': [max(0.6, best_params_precision['classifier__subsample'] - 0.025), min(1.0, best_params_precision['classifier__subsample'] + 0.025)],\n",
    "    'classifier__colsample_bytree': [max(0.6, best_params_precision['classifier__colsample_bytree'] - 0.025), min(1.0, best_params_precision['classifier__colsample_bytree'] + 0.025)],\n",
    "    'classifier__gamma': [max(0, best_params_precision['classifier__gamma']), best_params_precision['classifier__gamma'] + 0.025],\n",
    "    'classifier__reg_alpha': [best_params_precision['classifier__reg_alpha']],\n",
    "    'classifier__reg_lambda': [best_params_precision['classifier__reg_lambda']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_aucpr = random_search_aucpr.best_params_\n",
    "refined_param_grid_aucpr = {\n",
    "    'classifier__n_estimators': [max(100, best_params_aucpr['classifier__n_estimators'] - 25), best_params_aucpr['classifier__n_estimators'] + 25],\n",
    "    'classifier__learning_rate': [best_params_aucpr['classifier__learning_rate'] * 0.95, best_params_aucpr['classifier__learning_rate'] * 1.05],\n",
    "    'classifier__max_depth': [max(1, best_params_aucpr['classifier__max_depth']), best_params_aucpr['classifier__max_depth'] + 1],\n",
    "    'classifier__subsample': [max(0.6, best_params_aucpr['classifier__subsample'] - 0.025), min(1.0, best_params_aucpr['classifier__subsample'] + 0.025)],\n",
    "    'classifier__colsample_bytree': [max(0.6, best_params_aucpr['classifier__colsample_bytree'] - 0.025), min(1.0, best_params_aucpr['classifier__colsample_bytree'] + 0.025)],\n",
    "    'classifier__gamma': [max(0, best_params_aucpr['classifier__gamma']), best_params_aucpr['classifier__gamma'] + 0.025],\n",
    "    'classifier__reg_alpha': [best_params_aucpr['classifier__reg_alpha']],\n",
    "    'classifier__reg_lambda': [best_params_aucpr['classifier__reg_lambda']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb94e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Grid Search for Precision ---\n",
    "print(\"\\n--- Stage 2: Grid Search for Precision ---\")\n",
    "grid_search_precision = GridSearchCV(\n",
    "    estimator=pipeline_for_tuning,\n",
    "    param_grid=refined_param_grid_precision,\n",
    "    scoring='precision',\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_precision.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest parameters for Precision (Grid Search):\")\n",
    "print(grid_search_precision.best_params_)\n",
    "print(\"\\nBest Precision score (Grid Search):\")\n",
    "print(grid_search_precision.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bank_fraud.config import PROCESSED_DATA_DIR, REFERENCES_DIR, MODELS_DIR\n",
    "\n",
    "# Store Stage 1 best score for comparison\n",
    "random_search_precision_best_score_stage1 = random_search_precision.best_score_\n",
    "\n",
    "# Save the best model for Precision if it performs better than Stage 1\n",
    "if grid_search_precision.best_score_ > random_search_precision_best_score_stage1:\n",
    "    best_xgb_precision_model = grid_search_precision.best_estimator_\n",
    "    joblib.dump(best_xgb_precision_model, MODELS_DIR / 'best_xgb_precision_model.joblib')\n",
    "    print(f\"Best XGBoost model (Precision-optimized) saved to: {MODELS_DIR.relative_to(project_root) / 'best_xgb_precision_model.joblib'}\")\n",
    "else:\n",
    "    print(\"Stage 2 Grid Search for Precision did not improve upon Stage 1 Randomized Search. Model not saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d451c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Grid Search for AUC-PR ---\n",
    "print(\"\\n--- Stage 2: Grid Search for AUC-PR ---\")\n",
    "grid_search_aucpr = GridSearchCV(\n",
    "    estimator=pipeline_for_tuning,\n",
    "    param_grid=refined_param_grid_aucpr,\n",
    "    scoring='average_precision',\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_aucpr.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest parameters for AUC-PR (Grid Search):\")\n",
    "print(grid_search_aucpr.best_params_)\n",
    "print(\"\\nBest AUC-PR score (Grid Search):\")\n",
    "print(grid_search_aucpr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3727d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Stage 1 best score for comparison\n",
    "random_search_aucpr_best_score_stage1 = random_search_aucpr.best_score_\n",
    "\n",
    "# Save the best model for AUC-PR if it performs better than Stage 1\n",
    "if grid_search_aucpr.best_score_ > random_search_aucpr_best_score_stage1:\n",
    "    best_xgb_aucpr_model = grid_search_aucpr.best_estimator_\n",
    "    joblib.dump(best_xgb_aucpr_model, MODELS_DIR / 'best_xgb_aucpr_model.joblib')\n",
    "    print(f\"Best XGBoost model (AUC-PR-optimized) saved to: {MODELS_DIR.relative_to(project_root) / 'best_xgb_aucpr_model.joblib'}\")\n",
    "else:\n",
    "    print(\"Stage 2 Grid Search for AUC-PR did not improve upon Stage 1 Randomized Search. Model not saved.\")\n",
    "\n",
    "print(\"\\nHyperparameter tuning complete. Best models saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afa906",
   "metadata": {},
   "source": [
    "### 3.5.3. Summary of Hyperparameter Tuning Key Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e7224c",
   "metadata": {},
   "source": [
    "The two-stage hyperparameter tuning process for XGBoost models, optimized separately for Precision and Average Precision (AUC-PR), yielded the following key insights:\n",
    "\n",
    "**Overall Effectiveness:**\n",
    "The tuning process successfully identified improved hyperparameter configurations for XGBoost compared to the initial baseline model. This validates the approach of systematically searching the parameter space.\n",
    "\n",
    "**Precision-Optimized Model:**\n",
    "*   **Stage 1 (RandomizedSearchCV) Best Precision:** Achieved approximately **48.49%**.\n",
    "*   **Stage 2 (GridSearchCV) Best Precision:** Achieved **48.76%**.\n",
    "*   **Interpretation:** The `GridSearchCV` in Stage 2 provided a marginal improvement of **0.27 percentage points** over the best model found by `RandomizedSearchCV` in Stage 1. This indicates that Stage 1 was highly effective in locating a near-optimal region, and Stage 2 performed a successful, albeit fine-grained, refinement. The best model for Precision is now identified.\n",
    "\n",
    "**AUC-PR-Optimized Model:**\n",
    "*   **Stage 1 (RandomizedSearchCV) Best AUC-PR:** Achieved approximately **57.81%**.\n",
    "*   **Stage 2 (GridSearchCV) Best AUC-PR:** Achieved **57.89%**.\n",
    "*   **Interpretation:** Similar to Precision, the `GridSearchCV` in Stage 2 yielded a slight improvement of **0.08 percentage points** for AUC-PR compared to Stage 1. This confirms the robustness of the Stage 1 search and the successful fine-tuning in Stage 2. The best model for AUC-PR is now identified.\n",
    "\n",
    "**Conclusion:**\n",
    "The two-stage tuning process effectively refined the XGBoost models for both Precision and AUC-PR. While the gains from Stage 2 were marginal, they confirm the stability of the optimal regions identified by Stage 1. We now have two specialized, best-tuned XGBoost models ready for unbiased evaluation on the holdout dataset and subsequent business simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf941d",
   "metadata": {},
   "source": [
    "## 4. Holdout Evaluation and Business Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c4e009",
   "metadata": {},
   "source": [
    "In this section, we will evaluate the performance of our best-tuned models on the unseen holdout dataset.\n",
    "We will also conduct a cost-sensitive business simulation to understand the financial impact of our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6617a53",
   "metadata": {},
   "source": [
    "### 4.1. Load Best Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22218de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best Precision-optimized model\n",
    "best_xgb_precision_model = joblib.load(MODELS_DIR / 'best_xgb_precision_model.joblib')\n",
    "print(f\"Precision-optimized model loaded from: {MODELS_DIR.relative_to(project_root) / 'best_xgb_precision_model.joblib'}\")\n",
    "\n",
    "# Load the best AUC-PR-optimized model\n",
    "best_xgb_aucpr_model = joblib.load(MODELS_DIR / 'best_xgb_aucpr_model.joblib')\n",
    "print(f\"AUC-PR-optimized model loaded from: {MODELS_DIR.relative_to(project_root) / 'best_xgb_aucpr_model.joblib'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea001c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.2. Evaluate Models on Holdout Set\n",
    "\n",
    "def evaluate_model_on_holdout(model, X_holdout, y_holdout, model_name):\n",
    "    \"\"\"\n",
    "    Evaluates a given model on the holdout set and prints key metrics.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_holdout)\n",
    "    y_proba = model.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "    precision = precision_score(y_holdout, y_pred)\n",
    "    recall = recall_score(y_holdout, y_pred)\n",
    "    f1_weighted = f1_score(y_holdout, y_pred, average='weighted')\n",
    "    bal_acc = balanced_accuracy_score(y_holdout, y_pred)\n",
    "    mcc = matthews_corrcoef(y_holdout, y_pred)\n",
    "    ap = average_precision_score(y_holdout, y_proba)\n",
    "    brier = brier_score_loss(y_holdout, y_proba)\n",
    "\n",
    "    print(f\"\\n--- Holdout Evaluation for {model_name} ---\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Weighted: {f1_weighted:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {bal_acc:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "    print(f\"Average Precision (AUC-PR): {ap:.4f}\")\n",
    "    print(f\"Brier Score: {brier:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Weighted': f1_weighted,\n",
    "        'Balanced Accuracy': bal_acc,\n",
    "        'MCC': mcc,\n",
    "        'Average Precision (AUC-PR)': ap,\n",
    "        'Brier Score': brier\n",
    "    }\n",
    "\n",
    "# Evaluate Precision-optimized model\n",
    "precision_model_holdout_metrics = evaluate_model_on_holdout(best_xgb_precision_model, X_holdout, y_holdout, \"Precision-Optimized XGBoost\")\n",
    "\n",
    "# Evaluate AUC-PR-optimized model\n",
    "aucpr_model_holdout_metrics = evaluate_model_on_holdout(best_xgb_aucpr_model, X_holdout, y_holdout, \"AUC-PR-Optimized XGBoost\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
