{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f4da02",
   "metadata": {},
   "source": [
    "# 5.0 - Model Training, Evaluation, and Business Simulation\n",
    "\n",
    "_by Michael Joshua Vargas_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d454bf",
   "metadata": {},
   "source": [
    "This notebook implements the full machine learning workflow. It covers:\n",
    "1.  **Data Preparation**: Loading the final feature set and splitting it into training, validation, and holdout sets.\n",
    "2.  **Preprocessing**: Creating a robust pipeline to scale numerical features and one-hot encode categorical features.\n",
    "3.  **Model Tuning**: Training and tuning two separate XGBoost models optimized for different business goals (Precision and AUC-PR).\n",
    "4.  **Business Evaluation**: Using the tuned models on the holdout set to simulate a real-world, cost-sensitive fraud detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d58ca4",
   "metadata": {},
   "source": [
    "## Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "# --- Preprocessing & Modeling ---\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- Evaluation ---\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "# --- Model Persistence & Visualization ---\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress all warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ca4cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Path Setup ---\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = Path(os.getcwd())\n",
    "\n",
    "# Navigate up one level to reach the project root directory\n",
    "project_root = notebook_dir.parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import from config.py\n",
    "from bank_fraud.config import PROCESSED_DATA_DIR, REFERENCES_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcbba70",
   "metadata": {},
   "source": [
    "### Load Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c4c38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully from: data\\processed\\3.0_selected_features.parquet\n",
      "Dataset shape: (493189, 65)\n"
     ]
    }
   ],
   "source": [
    "# Load the final, curated dataset from the feature selection phase\n",
    "FINAL_DATA_PATH = PROCESSED_DATA_DIR / '3.0_selected_features.parquet'\n",
    "df = pd.read_parquet(FINAL_DATA_PATH)\n",
    "\n",
    "print(f\"Dataset loaded successfully from: {FINAL_DATA_PATH.relative_to(project_root)}\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb253a27",
   "metadata": {},
   "source": [
    "### Identify Feature Types and Define Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3786338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 identifier columns: ['profile_id', 'account_no']\n",
      "Identified 59 numerical features.\n",
      "Identified 3 categorical features.\n"
     ]
    }
   ],
   "source": [
    "# --- Dynamically Drop Identifier Columns ---\n",
    "\n",
    "# Load the identifier data dictionary to get the authoritative list of identifiers\n",
    "IDENTIFIER_DICT_PATH = REFERENCES_DIR / 'identifier_data_dictionary.csv'\n",
    "identifier_df = pd.read_csv(IDENTIFIER_DICT_PATH)\n",
    "all_identifiers = identifier_df['feature_name'].tolist()\n",
    "\n",
    "# Find which of these identifiers are actually present in our current DataFrame\n",
    "# This ensures the script doesn't fail if a column was already dropped in a previous step.\n",
    "identifiers_to_drop = [col for col in all_identifiers if col in df.columns]\n",
    "\n",
    "# Define the target variable\n",
    "TARGET_COL = 'fraud_status'\n",
    "\n",
    "# Define the feature matrix X by dropping the target and all identified identifiers\n",
    "X = df.drop(columns=[TARGET_COL] + identifiers_to_drop, errors='ignore')\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "print(f\"Dropped {len(identifiers_to_drop)} identifier columns: {identifiers_to_drop}\")\n",
    "\n",
    "\n",
    "# Identify numerical and categorical features from the final feature matrix X\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Identified {len(numerical_features)} numerical features.\")\n",
    "print(f\"Identified {len(categorical_features)} categorical features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ed50a",
   "metadata": {},
   "source": [
    "### Split Data into Training, Validation, and Holdout Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d94bdbf",
   "metadata": {},
   "source": [
    "We will perform a stratified split to ensure the proportion of fraud cases is consistent across all datasets.\n",
    "- **Training Set (70%)**: For training the model.\n",
    "- **Validation Set (15%)**: For tuning hyperparameters.\n",
    "- **Holdout Set (15%)**: For final, unbiased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ace76ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting complete.\n",
      "Training set shape:   (345232, 62)\n",
      "Validation set shape: (73978, 62)\n",
      "Holdout set shape:    (73979, 62)\n",
      "\n",
      "Proportion of fraud in each set:\n",
      "Training:   0.0166\n",
      "Validation: 0.0166\n",
      "Holdout:    0.0166\n"
     ]
    }
   ],
   "source": [
    "# First split: Create the training set (70%) and a temporary set (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.30, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Second split: Split the temporary set into validation (15%) and holdout (15%)\n",
    "# This is equivalent to splitting the 30% temp set in half (0.5)\n",
    "X_val, X_holdout, y_val, y_holdout = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=0.50, \n",
    "    random_state=42, \n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Data splitting complete.\")\n",
    "print(f\"Training set shape:   {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Holdout set shape:    {X_holdout.shape}\")\n",
    "print(\"\\nProportion of fraud in each set:\")\n",
    "print(f\"Training:   {y_train.mean():.4f}\")\n",
    "print(f\"Validation: {y_val.mean():.4f}\")\n",
    "print(f\"Holdout:    {y_holdout.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a001ec",
   "metadata": {},
   "source": [
    "### Establish Baseline with Proportion Chance Criterion (PCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475e2ca",
   "metadata": {},
   "source": [
    "Before building complex models, it's crucial to establish a baseline to understand the minimum performance we must exceed. For imbalanced classification tasks, simple accuracy can be misleading. The **Proportion Chance Criterion (PCC)** provides this baseline.\n",
    "\n",
    "The PCC represents the accuracy a naive model would achieve by always guessing the majority class. A common rule of thumb is that a useful model's accuracy should be at least 25% greater than the PCC.\n",
    "\n",
    "This calculation will demonstrate why we focus on metrics like Precision, Recall, and AUC-PR instead of accuracy alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93bd32b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion Chance Criterion (PCC): 96.74%\n",
      "1.25 * PCC Threshold: 120.92%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Calculate PCC on the training data\n",
    "class_counts = Counter(y_train)\n",
    "total_samples = len(y_train)\n",
    "\n",
    "pcc = ((class_counts[0] / total_samples)**2) + ((class_counts[1] / total_samples)**2)\n",
    "pcc_threshold = 1.25 * pcc\n",
    "\n",
    "print(f\"Proportion Chance Criterion (PCC): {pcc:.2%}\")\n",
    "print(f\"1.25 * PCC Threshold: {pcc_threshold:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14897f37",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "The PCC of approximately 0.97 indicates that a model that does nothing but predict 'NON_FRAUD' for every case would be about 97% accurate. This high value underscores the inadequacy of accuracy as a primary metric for this problem. Our model must demonstrate a much more nuanced understanding of the data to be considered effective, which is why our evaluation will focus on its ability to correctly identify the rare fraud cases (Precision and Recall)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c8523",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
